## Подшаг 3.2: Вычисление компонент функционала — подробный план реализации на C++

### Шаг 3.2.1: Архитектура вычислительного модуля

**Структура класса `FunctionalEvaluator`:**
- Инкапсулирует логику вычисления всех трёх компонент функционала
- Хранит ссылки на:
  * `ConstrainedPolynomial&` — аппроксимирующую функцию `F(x)`
  * `const DataSet&` — входные данные (точки, веса, запрещённые значения)
  * `const RegularizationParams&` — параметры регуляризации (`γ`, границы `[a, b]`)
- Предоставляет методы:
  * `compute_approximation_term()` — аппроксимирующий член
  * `compute_repulsion_term()` — отталкивающий член
  * `compute_regularization_term()` — регуляризационный член
  * `compute_total()` — полный функционал с детализацией по компонентам
  * `compute_gradient()` — градиент по свободным коэффициентам (см. шаг 3.3)

**Принцип разделения вычислений:**
- Каждая компонента вычисляется независимо для модульности и отладки
- Промежуточные результаты сохраняются для диагностики и анализа баланса критериев
- Возможность временного отключения компонент (для тестирования и настройки параметров)

### Шаг 3.2.2: Вычисление аппроксимирующего члена (взвешенный МНК)

**Математическая формула:**
```
J_approx = Σ_i |f(x_i) - F(x_i)|² / σ_i
```

**Алгоритм вычисления:**
1. **Подготовка данных:**
   - Извлечь массивы координат `x_i`, значений `f(x_i)` и весов `σ_i`
   - Проверить корректность весов: `σ_i > ε_weight` (защита от деления на ноль)
   - При необходимости нормализовать веса для улучшения численной устойчивости

2. **Оценка полинома в точках данных:**
   - Использовать кэшированные значения `F(x_i)`, вычисленные на этапе обновления коэффициентов
   - При отсутствии кэша — вызвать `polynomial.evaluate(x_i)` для каждой точки
   - Для повышения производительности применить пакетную обработку (batch evaluation)

3. **Вычисление взвешенных остатков:**
   - Для каждой точки вычислить разность: `residual_i = f(x_i) - F(x_i)`
   - Возвести в квадрат: `residual_sq = residual_i * residual_i`
   - Применить вес: `weighted_residual = residual_sq / σ_i`
   - Накопить сумму: `J_approx += weighted_residual`

4. **Численная защита:**
   - Контроль переполнения: если `|residual_i| > 1e10`, зафиксировать как аномалию
   - Проверка на `NaN/Inf` после каждого сложения с прерыванием вычислений при обнаружении
   - Логирование максимального абсолютного остатка для диагностики качества аппроксимации

5. **Оптимизация производительности:**
   - Векторизация вычислений через SIMD-инструкции (при компиляции с флагами `-O3 -march=native`)
   - Параллельное суммирование по блокам данных с последующим свертыванием (для больших наборов > 10⁴ точек)
   - Предварительное вычисление обратных весов `1/σ_i` для исключения деления в цикле

### Шаг 3.2.3: Вычисление отталкивающего члена с барьерной защитой

**Коррекция математической формулы:**
- Исходная формулировка `Σ B_j / |f(y_j) - F(y_j)|²` заменяется на корректную:
  ```
  J_repulse = Σ_j B_j / |y_j^* - F(y_j)|²
  ```
  где `y_j^*` — явно заданное запрещённое значение (не `f(y_j)`!)

**Алгоритм вычисления с многоуровневой защитой:**

1. **Подготовка барьерных параметров:**
   - Извлечь тройки `(y_j, y_j^*, B_j)` из структуры `RepulsionPoint`
   - Установить минимальный безопасный порог расстояния:
     ```
     ε_safe = max(1e-8, 1e-6 * max_range_y)
     где max_range_y = max(|y_j^*|, |F(y_j)|_initial)
     ```

2. **Оценка расстояний до запрещённых значений:**
   - Вычислить текущее значение полинома: `F_yj = polynomial.evaluate(y_j)`
   - Определить расстояние: `dist_j = |y_j^* - F_yj|`
   - Классифицировать ситуацию:
     * `dist_j > 10·ε_safe` — нормальный режим
     * `ε_safe < dist_j ≤ 10·ε_safe` — предупредительная зона (логирование)
     * `dist_j ≤ ε_safe` — критическая зона (барьерная защита)

3. **Барьерная защита от деления на ноль:**
   - Применить «смягчённый» барьер с плавным переходом:
     ```
     if (dist_j <= ε_safe) {
         // Квадратичное сглаживание в критической зоне
         term_j = B_j / (ε_safe² + k·(ε_safe - dist_j)²)
         где k = 10 — коэффициент сглаживания
     } else {
         term_j = B_j / dist_j²
     }
     ```
   - Альтернативный подход — логарифмический барьер для лучшей численной устойчивости:
     ```
     term_j = -B_j · log(max(dist_j, ε_safe))
     ```

4. **Динамическая адаптация силы барьера:**
   - При приближении к запрещённой точке (`dist_j < 2·ε_safe`) временно увеличить вес:
     ```
     effective_Bj = B_j · (1 + α · (2·ε_safe - dist_j) / ε_safe)
     где α = 5 — коэффициент усиления
     ```
   - Это создаёт «усиленный барьер» в непосредственной близости от запрещённой области

5. **Накопление и валидация:**
   - Суммировать все члены: `J_repulse += term_j`
   - Контролировать рост функционала: если `J_repulse > 1e12`, зафиксировать как признак несовместимости критериев
   - Для каждой точки сохранить расстояние `dist_j` для последующего анализа эффективности отталкивания

### Шаг 3.2.4: Вычисление регуляризационного члена (интеграл гладкости)

**Математическая формула:**
```
J_reg = γ · ∫_a^b [F''(x)]² dx
```

**Стратегия выбора метода вычисления:**

*Вариант A: Аналитическое вычисление (рекомендуется для полиномов)*
1. **Предварительное построение матрицы «жёсткости»:**
   - Для полинома `F(x) = Σ a_k · φ_k(x)` вторая производная: `F''(x) = Σ a_k · φ_k''(x)`
   - Интеграл раскладывается в квадратичную форму:
     ```
     ∫[F''(x)]²dx = Σ_k Σ_l a_k · a_l · ∫ φ_k''(x) · φ_l''(x) dx = a^T · H · a
     ```
   - Матрица `H` вычисляется один раз при инициализации:
     * Для мономиального базиса `φ_k(x) = x^k`:
       ```
       H_{kl} = ∫_a^b k(k-1)(k-2)x^{k-3} · l(l-1)(l-2)x^{l-3} dx
              = k(k-1)l(l-1) · (b^{k+l-3} - a^{k+l-3}) / (k+l-3)
       ```
     * Для базиса Чебышёва — использовать ортогональность для упрощения

2. **Эффективное вычисление на каждой итерации:**
   - После обновления коэффициентов `a` вычислить квадратичную форму:
     ```
     J_reg = γ · (a^T · H · a)
     ```
   - Сложность: O(n²) для плотной матрицы, O(n) для диагональной (ортогональный базис)

*Вариант B: Численное интегрирование (универсальный подход)*
1. **Выбор метода квадратур:**
   - Метод Гаусса-Лежандра с `N_quad = max(20, 2·n)` узлами — оптимальный баланс точности/скорости
   - Адаптивная квадратура для функций с локальными особенностями

2. **Алгоритм численного интегрирования:**
   - Преобразовать интервал `[a, b]` в стандартный `[-1, 1]` для применения табличных узлов Гаусса
   - Для каждого узла квадратуры `x_q`:
     * Вычислить `F''(x_q)` через метод `polynomial.second_derivative(x_q)`
     * Возвести в квадрат и умножить на вес квадратуры `w_q`
   - Суммировать: `integral += w_q · [F''(x_q)]²`
   - Применить масштабирующий коэффициент `(b - a)/2` для обратного преобразования интервала

3. **Контроль точности:**
   - Оценить погрешность через сравнение результатов с `N_quad` и `2·N_quad` узлами
   - При относительной разнице > `1e-6` автоматически увеличить число узлов

**Выбор стратегии в зависимости от контекста:**
- Для чистых полиномов — аналитический метод (точно, быстро)
- Для сплайнов или других базисов — численный метод
- Для отладки — параллельное вычисление обоими методами с проверкой согласованности

### Шаг 3.2.5: Суммирование компонент и управление масштабом

**Проблема несопоставимых масштабов:**
- Компоненты функционала могут различаться на порядки (например, `J_approx ~ 1`, `J_repulse ~ 1e6`)
- Это нарушает работу оптимизаторов, чувствительных к масштабу градиента

**Стратегия нормализации:**
1. **Автоматическое масштабирование при инициализации:**
   - Вычислить характерные масштабы каждой компоненты на начальном приближении:
     ```
     scale_approx = max(1.0, J_approx_initial)
     scale_repulse = max(1.0, J_repulse_initial)
     scale_reg = max(1.0, J_reg_initial)
     ```
   - Ввести нормализованные веса:
     ```
     w_approx = 1.0 / scale_approx
     w_repulse = 1.0 / scale_repulse
     w_reg = γ / scale_reg  // γ уже является весом регуляризации
     ```

2. **Вычисление нормализованного функционала:**
   ```
   J_normalized = w_approx · J_approx + w_repulse · J_repulse + w_reg · J_reg
   ```
   - Все компоненты вносят сопоставимый вклад в градиент
   - Пользовательские параметры `σ_i`, `B_j`, `γ` остаются физически интерпретируемыми

3. **Диагностика баланса критериев:**
   - Сохранять долю каждой компоненты в суммарном функционале:
     ```
     share_approx = w_approx·J_approx / J_normalized
     share_repulse = w_repulse·J_repulse / J_normalized
     share_reg = w_reg·J_reg / J_normalized
     ```
   - При доминировании одной компоненты (> 95%) выдавать рекомендацию по коррекции весов

### Шаг 3.2.6: Обработка крайних случаев и численных аномалий

**Сценарий 1: Пустые множества точек**
- Если `N_approx = 0` (нет аппроксимирующих точек):
  * Пропустить вычисление `J_approx` (вернуть 0)
  * Предупредить: «Аппроксимация основана только на интерполяции и отталкивании»
- Если `N_repulse = 0` (нет отталкивающих точек):
  * Пропустить вычисление `J_repulse` (вернуть 0)
  * Задача сводится к классической регуляризованной интерполяции

**Сценарий 2: Экстремальные значения функционала**
- При `J_repulse > 1e15`:
  * Зафиксировать «барьерный коллапс» — полином слишком близко к запрещённой точке
  * Автоматически уменьшить шаг оптимизатора на следующей итерации
  * Предложить уменьшить веса `B_j` или увеличить `ε_safe`
- При `J_reg < 1e-15` и `γ > 0`:
  * Проверить корректность вычисления интеграла (возможно, ошибка в матрице `H`)
  * Сравнить с численным интегрированием для верификации

**Сценарий 3: Конфликт критериев**
- Обнаружение конфликта: одновременно `J_approx > threshold` и `J_repulse > threshold`
  * Вычислить корреляцию между градиентами компонент
  * При сильной антикорреляции (> 0.9) выдать диагностику:
    «Критерии аппроксимации и отталкивания противоречивы в окрестности точки x=...»

### Шаг 3.2.7: Оптимизация производительности

**Кэширование промежуточных результатов:**
- Кэш значений полинома `F(x_i)`, `F(y_j)` — обновляется только при изменении коэффициентов
- Кэш вторых производных `F''(x_q)` для узлов квадратуры — постоянный (не зависит от коэффициентов для полиномов)
- Кэш расстояний `|y_j^* - F(y_j)|` — используется как в функционале, так и в градиенте

**Пакетная обработка:**
- Объединить вычисления `F(x_i)` и `F(y_j)` в единый проход для лучшего использования кэша CPU
- Для больших наборов (> 10⁵ точек) применить многопоточность через `std::async` или OpenMP:
  ```
  Разделить точки на блоки по 1000 элементов
  Запустить вычисление остатков в параллельных потоках
  Свести частичные суммы в критической секции
  ```

**Раннее прекращение вычислений:**
- При обнаружении `NaN/Inf` в любой компоненте немедленно прервать вычисления
- При превышении порога `J_total > 1e20` (признак расходимости) вернуть специальный код ошибки
- Для отладки — режим «строгой проверки» с валидацией каждого промежуточного результата

### Шаг 3.2.8: Диагностический вывод и валидация

**Формирование отчёта о вычислении функционала:**
```
Функционал смешанной аппроксимации:
  Аппроксимирующий член:  2.3456   (вес: 1.0000, доля: 45.2%)
  Отталкивающий член:     1.8765   (вес: 1.0000, доля: 36.1%)
  Регуляризация:          0.9721   (вес: 0.5000, доля: 18.7%)
  Итого:                  5.1942
   
Диагностика:
  Минимальное расстояние до запрещённых точек: 0.123 (порог: 1e-8)
  Максимальный остаток аппроксимации: 0.456
  Норма второй производной: 3.21 (мера гладкости)
```

**Валидация корректности вычислений:**
- Проверка неотрицательности всех компонент (кроме возможных логарифмических барьеров)
- Сравнение аналитического и численного интегралов при отладке (отклонение < 1e-8)
- Тест на воспроизводимость: повторное вычисление с теми же коэффициентами должно давать идентичный результат (с точностью до машинного эпсилон)

Этот план обеспечивает надёжное, численно устойчивое и производительное вычисление составного функционала с явной обработкой особенностей отталкивающего критерия и автоматической адаптацией к масштабам различных компонент. Подход поддерживает как аналитические оптимизации для полиномиальных базисов, так и универсальные численные методы для произвольных аппроксимирующих функций.