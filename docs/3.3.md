## Подшаг 3.3: Вычисление градиента функционала — подробный план реализации на C++

### Шаг 3.3.1: Математическая основа градиента с учётом параметризации

**Ключевой принцип:**
- Градиент вычисляется не по исходным коэффициентам полинома `a_k`, а по **свободным параметрам** корректирующего полинома `q_k` (размерность `n_free = n - m + 1`)
- Это обеспечивает автоматическое выполнение интерполяционных условий без метода множителей Лагранжа
- Для параметризации `F(x) = P_int(x) + Q(x)·W(x)` частная производная:
  ```
  ∂F(x)/∂q_k = φ_k(x) · W(x)
  ```
  где `φ_k(x)` — базисная функция для коэффициента `q_k` (например, `x^k` для мономиального базиса)

**Структура градиента:**
```
∇J = [∂J/∂q_0, ∂J/∂q_1, ..., ∂J/∂q_{n_free-1}]^T
```
Каждая компонента градиента представляет собой сумму вкладов от трёх частей функционала.

### Шаг 3.3.2: Градиент аппроксимирующего члена

**Аналитическая формула:**
```
∂J_approx/∂q_k = -2 · Σ_i [ (f(x_i) - F(x_i)) / σ_i ] · φ_k(x_i) · W(x_i)
```

**Алгоритм вычисления:**
1. **Подготовка промежуточных значений:**
   - Извлечь из кэша значения полинома `F(x_i)` и весового множителя `W(x_i)`
   - Вычислить остатки: `residual_i = f(x_i) - F(x_i)`
   - Применить веса: `weighted_residual_i = residual_i / σ_i`

2. **Вычисление базисных функций:**
   - Для каждой точки `x_i` вычислить значения всех базисных функций `φ_k(x_i)`:
     * Мономиальный базис: `φ_k(x_i) = x_i^k`
     * Базис Чебышёва: `φ_k(x_i) = T_k(t_i)`, где `t_i` — нормализованная координата
   - Кэшировать таблицу `basis_values[i][k]` для повторного использования в других компонентах градиента

3. **Накопление градиента:**
   - Для каждого свободного коэффициента `q_k`:
     ```
     grad_approx[k] = 0
     для каждой точки i:
         grad_approx[k] -= 2.0 * weighted_residual_i * basis_values[i][k] * W_cache_x[i]
     ```
   - Сложность: O(N_approx · n_free), где `N_approx` — число аппроксимирующих точек

4. **Численная защита:**
   - Контроль переполнения: если `|weighted_residual_i| > 1e10`, ограничить значение порогом
   - Проверка на `NaN` после каждого накопления с прерыванием при обнаружении аномалии
   - Для очень больших наборов данных применить компенсированное суммирование (алгоритм Кахана) для уменьшения ошибки округления

### Шаг 3.3.3: Градиент отталкивающего члена с барьерной защитой

**Коррекция математической формулы:**
- Исходная формулировка с `f(y_j)` заменяется на корректную с запрещённым значением `y_j^*`:
  ```
  ∂J_repulse/∂q_k = +2 · Σ_j [ B_j / |y_j^* - F(y_j)|³ ] · sign(y_j^* - F(y_j)) · φ_k(y_j) · W(y_j)
  ```
  где `sign(·)` — знак разности (обеспечивает направление градиента «от барьера»)

**Алгоритм вычисления с многоуровневой защитой:**

1. **Подготовка расстояний до запрещённых значений:**
   - Извлечь из кэша (или вычислить) значения `F(y_j)` и `W(y_j)`
   - Вычислить расстояния: `dist_j = y_j^* - F(y_j)` (со знаком!)
   - Сохранить абсолютные расстояния: `abs_dist_j = |dist_j|`

2. **Классификация зон приближения к барьеру:**
   - Установить пороги:
     ```
     ε_critical = 1e-8          // критическая зона
     ε_warning  = 1e-4          // предупредительная зона
     ```
   - Для каждой точки определить режим:
     * `abs_dist_j > ε_warning` — нормальный режим
     * `ε_critical < abs_dist_j ≤ ε_warning` — предупредительная зона
     * `abs_dist_j ≤ ε_critical` — критическая зона (барьерная защита)

3. **Вычисление защищённого градиента в критической зоне:**
   - Применить сглаживающую функцию для предотвращения взрывного роста градиента:
     ```
     если abs_dist_j <= ε_critical:
         // Кубическое сглаживание в критической зоне
         factor = B_j / (ε_critical³ + k·(ε_critical - abs_dist_j)³)
         где k = 5 — коэффициент сглаживания
     иначе если abs_dist_j <= ε_warning:
         // Плавный переход к стандартной формуле
         α = (abs_dist_j - ε_critical) / (ε_warning - ε_critical)
         factor = B_j · [α / abs_dist_j³ + (1-α) / ε_critical³]
     иначе:
         // Стандартная формула
         factor = B_j / abs_dist_j³
     ```
   - Направление градиента определяется знаком `dist_j`:
     ```
     direction = sign(dist_j)  // +1 если F < y*, -1 если F > y*
     ```

4. **Накопление градиента:**
   - Для каждого свободного коэффициента `q_k`:
     ```
     grad_repulse[k] = 0
     для каждой отталкивающей точки j:
         grad_repulse[k] += 2.0 * factor_j * direction_j * basis_values_y[j][k] * W_cache_y[j]
     ```
   - Логирование точек в критической зоне для диагностики «барьерного коллапса»

5. **Динамическая адаптация при оптимизации:**
   - Сохранить максимальное значение `|grad_repulse[k]|` для всех `k`
   - При превышении порога `max_grad > 1e8`:
     * Уменьшить шаг оптимизатора на следующей итерации
     * Предложить уменьшить веса `B_j` или увеличить `ε_critical`

### Шаг 3.3.4: Градиент регуляризационного члена (аналитический подход)

**Математическая основа для полиномиального базиса:**
- Для параметризации `F(x) = P_int(x) + Q(x)·W(x)` вторая производная:
  ```
  F''(x) = P_int''(x) + Q''(x)·W(x) + 2·Q'(x)·W'(x) + Q(x)·W''(x)
  ```
- Регуляризационный член:
  ```
  J_reg = γ · ∫[F''(x)]²dx = γ · ∫[P_int'' + (Q·W)'']²dx
  ```
- Градиент по коэффициенту `q_k`:
  ```
  ∂J_reg/∂q_k = 2γ · ∫[F''(x)] · ∂[F''(x)]/∂q_k dx
              = 2γ · ∫[F''(x)] · [φ_k''(x)·W(x) + 2·φ_k'(x)·W'(x) + φ_k(x)·W''(x)] dx
  ```

**Эффективная реализация через предварительно вычисленную матрицу:**

1. **Построение матрицы регуляризации при инициализации:**
   - Вычислить матрицу `R` размером `n_free × n_free`:
     ```
     R_{kl} = ∫ [φ_k''·W + 2·φ_k'·W' + φ_k·W''] · [φ_l''·W + 2·φ_l'·W' + φ_l·W''] dx
     ```
   - Для мономиального базиса интегралы вычисляются аналитически:
     ```
     ∫ x^p · x^q dx = (b^{p+q+1} - a^{p+q+1}) / (p+q+1)
     ```
   - Для базиса Чебышёва использовать ортогональность и рекуррентные соотношения

2. **Вычисление градиента на каждой итерации:**
   - Вектор свободных коэффициентов: `q = [q_0, q_1, ..., q_{n_free-1}]^T`
   - Градиент регуляризации:
     ```
     grad_reg = 2γ · R · q
     ```
   - Сложность: O(n_free²) для плотной матрицы, O(n_free) для диагональной

3. **Учёт вклада базисного полинома `P_int(x)`:**
   - Дополнительный вектор `c` размером `n_free`:
     ```
     c_k = ∫ P_int''(x) · [φ_k''(x)·W(x) + 2·φ_k'(x)·W'(x) + φ_k(x)·W''(x)] dx
     ```
   - Полный градиент:
     ```
     grad_reg = 2γ · (R · q + c)
     ```
   - Вектор `c` вычисляется один раз при инициализации (не зависит от `q`)

### Шаг 3.3.5: Сборка полного градиента и нормализация масштаба

**Суммирование компонент:**
```
∇J[k] = grad_approx[k] + grad_repulse[k] + grad_reg[k]
```

**Проблема несопоставимых масштабов градиента:**
- Компоненты градиента могут различаться на порядки, что нарушает работу оптимизаторов
- Пример: `|grad_approx| ~ 1`, `|grad_repulse| ~ 1e6`, `|grad_reg| ~ 0.01`

**Стратегия адаптивной нормализации:**

1. **Оценка характерных масштабов при инициализации:**
   - Вычислить евклидовы нормы каждой компоненты градиента на начальном приближении:
     ```
     norm_approx = ||grad_approx||
     norm_repulse = ||grad_repulse||
     norm_reg = ||grad_reg||
     ```
   - Установить нормализующие коэффициенты:
     ```
     α_approx  = 1.0 / max(1.0, norm_approx)
     α_repulse = 1.0 / max(1.0, norm_repulse)
     α_reg     = 1.0 / max(1.0, norm_reg)
     ```

2. **Нормализованный градиент:**
   ```
   ∇J_normalized[k] = α_approx·grad_approx[k] + α_repulse·grad_repulse[k] + α_reg·grad_reg[k]
   ```
   - Все компоненты вносят сопоставимый вклад в направление шага оптимизации
   - Физический смысл весов `σ_i`, `B_j`, `γ` сохраняется через пропорциональность

3. **Динамическая адаптация масштабов:**
   - На каждой итерации оценивать отношение норм компонент:
     ```
     ratio_repulse_approx = ||grad_repulse|| / ||grad_approx||
     ```
   - При сильном дисбалансе (`ratio > 100` или `ratio < 0.01`) постепенно корректировать нормализующие коэффициенты:
     ```
     α_repulse_new = α_repulse · (1.0 + β · log10(ratio))
     где β = 0.1 — коэффициент адаптации
     ```

### Шаг 3.3.6: Численная верификация градиента (метод конечных разностей)

**Цель верификации:**
- Обнаружить ошибки в аналитических формулах градиента до запуска оптимизации
- Особенно критично для сложного отталкивающего члена с барьерной защитой

**Алгоритм верификации:**

1. **Выбор контрольной точки:**
   - Использовать начальное приближение коэффициентов `q_initial`
   - Выбрать случайный индекс компоненты `k_test` для проверки

2. **Вычисление численного градиента:**
   - Шаг конечных разностей: `h = 1e-6 · max(1.0, |q_k|)`
   - Возмущение вперёд: `q_plus = q_initial`; `q_plus[k_test] += h`
   - Возмущение назад: `q_minus = q_initial`; `q_minus[k_test] -= h`
   - Численная оценка:
     ```
     grad_numeric = (J(q_plus) - J(q_minus)) / (2·h)
     ```

3. **Сравнение с аналитическим градиентом:**
   - Относительная ошибка:
     ```
     ε_rel = |grad_analytic[k_test] - grad_numeric| / max(|grad_analytic|, |grad_numeric|, 1e-12)
     ```
   - Критерий корректности: `ε_rel < 1e-6`
   - При нарушении критерия:
     * Логировать компоненту с ошибкой
     * Указать возможную причину (например, «некорректная обработка барьера в точке y_j=...»)
     * Предложить режим отладки с пошаговой верификацией каждой компоненты

4. **Полная верификация (опционально):**
   - Проверить все компоненты градиента при отладке
   - Построить график относительных ошибок для визуальной диагностики систематических отклонений

### Шаг 3.3.7: Оптимизация производительности вычисления градиента

**Кэширование промежуточных результатов:**
- **Таблица базисных функций:** `basis_cache_x[i][k] = φ_k(x_i)` для всех аппроксимирующих точек
- **Таблица производных базиса:** `basis_deriv1_cache[k]`, `basis_deriv2_cache[k]` для регуляризации
- **Значения весового множителя:** `W_cache_x[i]`, `W_cache_y[j]` — вычисляются один раз при изменении узлов интерполяции
- **Расстояния до запрещённых значений:** `dist_cache[j] = y_j^* - F(y_j)` — обновляются при каждом изменении `q`

**Векторизация вычислений:**
- Организовать данные в порядке, благоприятном для SIMD:
  * Массивы значений базисных функций хранить в транспонированном виде: `[k][i]` вместо `[i][k]`
  * Это позволяет загружать 4–8 значений `φ_k(x_i)` в один векторный регистр
- Для компилятора указать выравнивание памяти (`alignas(32)`) для массивов кэша
- Использовать интринсики или довериться автовекторизации компилятора при флагах `-O3 -march=native`

**Параллельные вычисления:**
- Для больших наборов данных (> 10⁴ точек) применить многопоточность:
  * Разделить точки на блоки по количеству логических ядер CPU
  * Каждый поток вычисляет частичный градиент по своему блоку точек
  * Сведение частичных градиентов в критической секции или через атомарные операции
- Для регуляризационного члена параллелизация менее эффективна (низкая размерность `n_free`)

**Раннее прекращение при обнаружении аномалий:**
- После обработки каждого блока точек проверять накопленный градиент на `NaN/Inf`
- При обнаружении аномалии немедленно прервать вычисления и вернуть код ошибки
- Логировать точку данных, вызвавшую аномалию, для диагностики

### Шаг 3.3.8: Диагностический вывод и валидация градиента

**Формирование отчёта о градиенте:**
```
Градиент функционала (нормализованный):
  Компонента      Норма      Макс. элемент   Мин. элемент
  -------------------------------------------------------
  Аппроксимация   2.345      +1.876          -2.103
  Отталкивание    1.987      +3.421          -0.876
  Регуляризация   0.543      +0.321          -0.432
  -------------------------------------------------------
  Итого           4.123      +5.123          -2.543

Диагностика:
  Макс. расстояние до барьера: 0.234 (безопасно)
  Отн. ошибка верификации: 2.3e-8 (в пределах допуска)
  Баланс компонент: аппроксимация=57%, отталкивание=48%, регуляризация=13%
```

**Валидация корректности:**
- Проверка отсутствия `NaN/Inf` в любой компоненте градиента
- Контроль знака градиента отталкивания: должен указывать «от барьера»
  * Если `F(y_j) < y_j^*`, то градиент должен «толкать» функцию вверх (`∂J/∂q_k > 0` для возрастающих базисных функций)
- Тест на линейность: для линейного функционала градиент должен быть постоянным (проверка на простых тестовых задачах)

Этот план обеспечивает точное, численно устойчивое и производительное вычисление градиента составного функционала с явной обработкой особенностей барьерного отталкивания и автоматическим удовлетворением интерполяционных ограничений через параметризацию пространства решений. Встроенные механизмы верификации и диагностики позволяют обнаруживать ошибки на ранних этапах разработки и обеспечивать надёжность оптимизационного процесса.