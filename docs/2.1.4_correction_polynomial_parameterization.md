## Подшаг 2.1.4: Параметризация корректирующего полинома `Q(x)` — подробный план реализации на C++

### Шаг 2.1.4.1: Определение размерности пространства свободных параметров

**Расчёт эффективной степени корректирующего полинома:**
- Вычислить степень: `deg_Q = n - m`, где `n` — степень итогового полинома `F(x)`, `m` — число интерполяционных узлов
- Проверить неотрицательность: `deg_Q ≥ 0` (гарантируется валидацией шага 1.1, но повторная проверка обязательна)
- Определить количество свободных параметров: `n_free = deg_Q + 1`
- Специальные случаи:
  * `deg_Q = -1` (теоретически при `m = n + 1`): корректирующий полином вырождается в тождественный ноль
  * `deg_Q = 0`: константная коррекция (один свободный параметр)
  * `deg_Q ≥ 1`: полноценный полином с множеством степеней свободы

**Анализ достаточности параметров для задачи:**
- Сравнить `n_free` с числом аппроксимирующих точек `N_x`:
  * Если `n_free > N_x` — риск переобучения; рекомендовать увеличение `γ` или снижение `n`
  * Если `n_free ≪ N_x` — возможна недоадаптация; рассмотреть увеличение `n`
- Оценить соотношение `n_free / (N_x + N_y)` как индикатор баланса гибкости и данных

### Шаг 2.1.4.2: Выбор базиса представления полинома `Q(x)`

**Мономиальный базис (стандартный):**
- Представление: `Q(x) = q_0 + q_1·x + q_2·x² + ... + q_{deg_Q}·x^{deg_Q}`
- Преимущества:
  * Простота реализации и интерпретации коэффициентов
  * Прямое соответствие классическому представлению полиномов
  * Лёгкость вычисления производных (аналитические формулы)
- Недостатки:
  * Плохая обусловленность матрицы Грама при `deg_Q > 10`
  * Численная неустойчивость из-за корреляции базисных функций `x^k`
  * Проблема Рунге при интерполяции на равномерной сетке

**Ортогональный базис Чебышёва (рекомендуемый для `deg_Q > 5`):**
- Нормализация координат к интервалу `[-1, 1]`:
  ```
  t = 2·(x - x_center) / x_scale - 1, где x_center = (a + b)/2, x_scale = b - a
  ```
- Представление: `Q(x) = Σ_{k=0..deg_Q} q_k · T_k(t)`, где `T_k(t)` — полиномы Чебышёва первого рода
- Рекуррентное определение полиномов Чебышёва:
  * `T_0(t) = 1`
  * `T_1(t) = t`
  * `T_{k+1}(t) = 2·t·T_k(t) - T_{k-1}(t)`
- Преимущества:
  * Ортогональность базиса минимизирует корреляцию параметров
  * Равномерное распределение ошибки по интервалу (минимаксное свойство)
  * Устойчивость к осцилляциям при высоких степенях
- Недостатки:
  * Требует преобразования координат при каждом вычислении
  * Сложнее интерпретировать физический смысл коэффициентов

**Стратегия выбора базиса:**
- Если `deg_Q ≤ 5` — использовать мономиальный базис (простота превалирует)
- Если `5 < deg_Q ≤ 15` — использовать базис Чебышёва с нормализацией
- Если `deg_Q > 15` — обязательное использование Чебышёва + предупреждение о потенциальной неустойчивости глобального полинома

### Шаг 2.1.4.3: Проектирование структуры данных для хранения параметров

**Основная структура `CorrectionPolynomial`:**
```cpp
struct CorrectionPolynomial {
    // Параметры базиса
    BasisType basis_type;                // MONOMIAL или CHEBYSHEV
    int degree;                          // deg_Q = n - m
    int n_free;                          // n_free = deg_Q + 1
    
    // Коэффициенты (вектор свободных параметров для оптимизатора)
    std::vector<double> coeffs;          // q_0, q_1, ..., q_{deg_Q}
    
    // Параметры нормализации (для базиса Чебышёва)
    double x_center;                     // центр интервала [a, b]
    double x_scale;                      // масштаб интервала
    
    // Кэшированные данные для ускорения вычислений
    std::vector<std::vector<double>> basis_cache_x;   // φ_k(x_i) для всех точек и базисных функций
    std::vector<std::vector<double>> basis_cache_y;   // φ_k(y_j) для всех точек и базисных функций
    std::vector<std::vector<double>> basis2_cache_x;  // φ_k''(x_i) для регуляризации
    
    // Метаданные состояния
    bool is_initialized;
    InitializationMethod init_method;    // ZERO, LEAST_SQUARES, RANDOM
};
```

**Вспомогательная структура базисных функций:**
- Для мономиального базиса: `φ_k(x) = x^k`
- Для базиса Чебышёва: `φ_k(x) = T_k(t(x))`, где `t(x)` — нормализованная координата
- Хранить указатель на функцию вычисления базисной функции для гибкости расширения

### Шаг 2.1.4.4: Инициализация коэффициентов корректирующего полинома

**Стратегия нулевой инициализации (базовая):**
- Установить все коэффициенты в ноль: `q_k = 0` для всех `k`
- Результат: начальное приближение `F(x) = P_int(x)` (чистая интерполяция без коррекции)
- Преимущества:
  * Гарантированное выполнение интерполяционных условий
  * Простота и предсказуемость
  * Хорошая отправная точка при умеренных весах отталкивания
- Недостатки:
  * Может быть далеко от оптимума при сильном доминировании аппроксимирующего критерия
  * Риск застревания в локальном минимуме при сложной топологии функционала

**Стратегия инициализации через взвешенный МНК (рекомендуемая):**
1. Построить временную целевую функцию только по аппроксимирующим точкам:
   ```
   F_temp(x_i) ≈ f(x_i),  i = 1..N_x
   ```
2. Решить задачу взвешенного МНК для полинома степени `n`:
   * Матрица системы: `A[i][k] = φ_k(x_i) · W(x_i)` (учитывает весовой множитель)
   * Вектор правой части: `b[i] = (f(x_i) - P_int(x_i)) / √σ_i`
   * Решение: `q = (AᵀA)⁻¹Aᵀb` через QR-разложение или SVD для устойчивости
3. Преимущества:
   * Начальное приближение уже близко к оптимуму по аппроксимирующему критерию
   * Уменьшение числа итераций оптимизации
   * Снижение риска застревания в плохих локальных минимумах
4. Недостатки:
   * Требует решения линейной системы (дополнительные вычисления)
   * Может нарушать «безопасное» расстояние от отталкивающих точек (требует пост-проверки)

**Гибридная стратегия с защитой от барьеров:**
1. Выполнить инициализацию через МНК
2. Проверить расстояние до отталкивающих точек:
   * Для каждой точки `y_j` вычислить `d_j = |y_j^* - F(y_j)|`
   * Если `d_j < d_safe = 0.1·min_{i}|f(x_i) - y_j^*|` — уменьшить все коэффициенты пропорционально:
     ```
     scale_factor = min(1.0, d_safe / min_j(d_j))
     q_k = q_k · scale_factor
     ```
3. Результат: компромисс между близостью к данным и безопасным расстоянием от барьеров

### Шаг 2.1.4.5: Предварительное вычисление базисных функций и их производных

**Кэширование значений базиса в точках данных:**
1. Для аппроксимирующих точек `{x_i}`:
   - Для каждого узла `x_i` и каждой базисной функции `φ_k`:
     * Вычислить значение: `φ_k(x_i)`
     * Вычислить первую производную: `φ_k'(x_i)` (для градиента)
     * Вычислить вторую производную: `φ_k''(x_i)` (для регуляризации)
   - Сохранить в трёхмерном кэше: `basis_cache_x[i][k][derivative_order]`

2. Для отталкивающих точек `{y_j}`:
   - Аналогичное кэширование в отдельной структуре `basis_cache_y`

3. Для численного интегрирования регуляризационного члена:
   - Сгенерировать узлы квадратуры Гаусса-Лежандра на `[a, b]` (10–20 точек)
   - Вычислить значения базисных функций и их вторых производных во всех узлах квадратуры

**Оптимизация кэширования для базиса Чебышёва:**
- Использовать рекуррентные соотношения для одновременного вычисления всех `T_k(t)` за один проход:
  ```
  T_prev = 1.0        // T_0
  T_curr = t          // T_1
  для k от 2 до deg_Q:
      T_next = 2*t*T_curr - T_prev
      T_prev = T_curr
      T_curr = T_next
  ```
- Аналогично для производных через рекуррентные формулы:
  ```
  T_0' = 0
  T_1' = 1
  T_{k+1}' = 2·T_k + 2·t·T_k' - T_{k-1}'
  ```

### Шаг 2.1.4.6: Подготовка данных для вычисления градиента функционала

**Аналитический градиент по коэффициентам `q_k`:**
Градиент составного функционала раскладывается на три компонента:

1. **Градиент аппроксимирующего члена:**
   ```
   ∂J_approx/∂q_k = 2 · Σ_i [(F(x_i) - f(x_i)) / σ_i] · φ_k(x_i) · W(x_i)
   ```
   - Требует: закэшированных значений `φ_k(x_i)`, `W(x_i)`, и текущего `F(x_i)`

2. **Градиент отталкивающего члена:**
   ```
   ∂J_repulse/∂q_k = -2 · Σ_j [B_j / (y_j^* - F(y_j))³] · φ_k(y_j) · W(y_j)
   ```
   - Критическая защита: при `|y_j^* - F(y_j)| < ε_safe` ограничить множитель сверху:
     ```
     factor = min( max_value, B_j / max(ε_safe³, |y_j^* - F(y_j)|³) )
     ```
   - `ε_safe = 1e-4`, `max_value = 1e8` — эмпирические пороги для предотвращения взрывного роста градиента

3. **Градиент регуляризационного члена:**
   ```
   ∂J_reg/∂q_k = 2γ · Σ_l q_l · K_{kl}
   где K_{kl} = ∫ [φ_k(x)·W(x)]'' · [φ_l(x)·W(x)]'' dx
   ```
   - Предварительно вычислить матрицу «жёсткости» `K` размером `n_free × n_free`:
     * Для каждой пары `(k, l)` вычислить интеграл численно через квадратуру Гаусса
     * Использовать закэшированные вторые производные базисных функций
     * Симметрия матрицы позволяет вычислить только верхний треугольник

**Организация данных для эффективного вычисления градиента:**
- Предварительно вычислить и сохранить:
  * Вектор `v_approx[k] = Σ_i [φ_k(x_i) · W(x_i) / σ_i]` — для линейной части градиента
  * Матрицу `M_repulse[k][j] = φ_k(y_j) · W(y_j)` — для нелинейной части
  * Матрицу `K[k][l]` — для регуляризационной части
- При каждой итерации оптимизации:
  * Вычислить текущие значения `F(x_i)` и `F(y_j)` через кэшированные данные
  * Собрать градиент как линейную комбинацию предварительно вычисленных структур

### Шаг 2.1.4.7: Верификация корректности параметризации

**Тест на линейную независимость базисных функций:**
1. Построить матрицу значений базиса в контрольных точках:
   ```
   G[i][k] = φ_k(x_test_i),  i = 1..n_free,  k = 0..deg_Q
   ```
   где `x_test_i` — равномерно распределённые точки на `[a, b]`
2. Вычислить число обусловленности матрицы `G` через SVD:
   * `cond(G) = σ_max / σ_min`, где `σ` — сингулярные значения
   * При `cond(G) > 1e10` — предупреждение о потенциальной неустойчивости
3. Для базиса Чебышёва ожидаемое число обусловленности: `cond(G) < 100` даже при `deg_Q = 20`

**Тест на полноту пространства коррекций:**
1. Сгенерировать `n_free` линейно независимых наборов коэффициентов `{q^{(1)}, q^{(2)}, ..., q^{(n_free)}}`
2. Построить соответствующие корректирующие функции `ΔF^{(k)}(x) = Q^{(k)}(x)·W(x)`
3. Проверить линейную независимость системы `{ΔF^{(k)}(x)}` через определитель матрицы значений в `n_free` точках
4. Убедиться, что ранг системы равен `n_free` (полная размерность подпространства)

**Тест на корректность инициализации:**
1. Вычислить начальное значение функционала `J_initial` для инициализированных коэффициентов
2. Сравнить с «наивным» решением (нулевые коэффициенты):
   * Если `J_initial > 10·J_naive` — диагностировать ошибку инициализации
3. Проверить расстояние до отталкивающих точек:
   * Минимальное расстояние `min_j |y_j^* - F(y_j)|` должно превышать `ε_safe = 1e-3`
   * При нарушении — применить стратегию масштабирования из шага 2.1.4.4

### Шаг 2.1.4.8: Интеграция с полной параметризацией решения

**Сборка итогового полинома через ленивую оценку:**
- Не вычислять явно коэффициенты `F(x)`, а оценивать «на лету»:
  ```
  F(x) = P_int.evaluate(x) + Q.evaluate(x) * W.evaluate(x)
  ```
- Преимущества:
  * Избегание численной неустойчивости при перемножении полиномов высокой степени
  * Возможность использования разных представлений для компонентов (барицентрическое для `P_int`, корни для `W`, Чебышёв для `Q`)
  * Естественное кэширование промежуточных результатов

**Интерфейс для оптимизатора:**
- Метод `compute_objective(const std::vector<double>& q)`:
  * Принимает вектор коэффициентов `q` длины `n_free`
  * Возвращает значение функционала `J(q)` через ленивую оценку
  * Использует все предварительно вычисленные кэши для максимальной эффективности
  
- Метод `compute_gradient(const std::vector<double>& q, std::vector<double>& grad)`:
  * Вычисляет градиент функционала по формуле из шага 2.1.4.6
  * Заполняет выходной вектор `grad` размером `n_free`
  * Возвращает флаг успеха (ложь при обнаружении численных аномалий)

**Подготовка диагностического отчёта:**
- Сводная информация о параметризации:
  * Степень корректирующего полинома: `deg_Q`
  * Число свободных параметров: `n_free`
  * Выбранный базис: `basis_type`
  * Метод инициализации: `init_method`
  * Число обусловленности базиса: `cond(G)`
- Рекомендации:
  * При `deg_Q > 15`: «Рассмотрите использование сплайнов вместо глобального полинома»
  * При `cond(G) > 1e8`: «Рекомендуется переключиться на базис Чебышёва»
  * При `n_free > N_x`: «Высокий риск переобучения; увеличьте γ или уменьшите степень полинома»

Этот план обеспечивает гибкую и численно устойчивую параметризацию корректирующего полинома с автоматическим выбором оптимального базиса, защитой от численных аномалий при инициализации, и полной подготовкой всех необходимых компонентов (значений базиса, производных, матрицы жёсткости) для эффективной оптимизации составного функционала в последующих этапах алгоритма.