## Подшаг 5.2: Масштабирование переменных — подробный план реализации на C++

### Шаг 5.2.1: Теоретическое обоснование необходимости масштабирования

**Проблемы неотмасштабированных данных:**
- **Плохая обусловленность матрицы Грама:** Для мономиального базиса элементы матрицы `A_{kl} = Σ x_i^{k+l}` различаются на порядки при `|x| >> 1` или `|x| << 1`, что приводит к `cond(A) > 1e15` и потере точности
- **Несбалансированность критериев:** Аппроксимирующий член может доминировать над регуляризацией из-за различий в масштабах `x` и `y`
- **Численная неустойчивость высоких степеней:** Вычисление `x^k` при `|x| > 10` и `k > 20` вызывает переполнение; при `|x| < 0.1` — потерю значащих цифр

**Принципы эффективного масштабирования:**
- **Независимое преобразование осей:** Масштабировать `x` и `y` отдельно для сохранения геометрического смысла задачи
- **Линейные преобразования:** Использовать аффинные преобразования для обратимости и сохранения полиномиальной структуры
- **Стандартные интервалы:** Приводить `x` к `[-1, 1]` (оптимально для полиномов Чебышёва) или `[0, 1]`; `y` к `[-1, 1]` или `[0, 1]`

### Шаг 5.2.2: Выбор стратегии нормализации для каждой оси

**Стратегия для оси абсцисс (координата `x`):**
1. **Линейное преобразование в интервал `[-1, 1]`:**
   ```
   t = 2·(x - x_center) / x_range
   где:
     x_center = (x_min + x_max) / 2
     x_range  = max(x_max - x_min, ε_range)
     x_min = min( min(x_i), min(y_j), min(z_e), a )
     x_max = max( max(x_i), max(y_j), max(z_e), b )
   ```
   - Преимущества: симметрия относительно нуля уменьшает корреляцию между коэффициентами полинома; оптимально для базиса Чебышёва
   - Обратное преобразование: `x = x_center + t·x_range/2`

2. **Альтернатива для несимметричных данных:** Преобразование в `[0, 1]` при наличии естественной нижней границы (например, время ≥ 0):
   ```
   t = (x - x_min) / x_range
   ```

**Стратегия для оси ординат (значение `y`):**
1. **Стандартизация с центрированием:**
   ```
   v = (y - y_center) / y_scale
   где:
     y_center = median( {f(x_i)} ∪ {y_j^*} ∪ {f(z_e)} )
     y_scale  = max( std({f(x_i)}), ε_scale )
   ```
   - Медиана вместо среднего устойчива к выбросам
   - Стандартное отклонение обеспечивает естественный масштаб вариации данных

2. **Альтернатива для строго положительных данных:** Логарифмическое преобразование перед линейным масштабированием:
   ```
   если min(y) > 0 И max(y)/min(y) > 100:
       v = log(y)
       затем применить линейное масштабирование к v
   ```

**Особые случаи:**
- Если `x_range < ε_range = 1e-12·max(1, |x_center|)` → данные вырождены, требуется предварительная обработка (удаление дубликатов)
- Если `y_scale < ε_scale = 1e-12·max(1, |y_center|)` → данные константны, задача тривиальна

### Шаг 5.2.3: Реализация прямого преобразования входных данных

**Этап 3.1: Вычисление параметров преобразования:**
1. **Сбор статистики по всем точкам:**
   - Объединить все множества точек в единый анализируемый набор:
     * Аппроксимирующие: `(x_i, f(x_i))`
     * Отталкивающие: `(y_j, y_j^*)` — обе координаты участвуют в статистике
     * Интерполяционные: `(z_e, f(z_e))`
   - Вычислить глобальные минимумы/максимумы для `x` и `y` с учётом границ интервала `[a, b]`

2. **Вычисление параметров преобразования `x → t`:**
   ```
   x_min_global = min(a, min_x_over_all_points)
   x_max_global = max(b, max_x_over_all_points)
   x_center = 0.5 * (x_min_global + x_max_global)
   x_range  = max(x_max_global - x_min_global, 1e-12 * max(1.0, fabs(x_center)))
   t_scale  = 2.0 / x_range
   t_shift  = -x_center * t_scale
   ```

3. **Вычисление параметров преобразования `y → v`:**
   ```
   // Сбор всех значений y для статистики
   values_y = { f(x_i) } ∪ { y_j^* } ∪ { f(z_e) }
   y_center = compute_median(values_y)
   y_scale  = compute_robust_std(values_y)  // медианное абсолютное отклонение × 1.4826
   y_scale  = max(y_scale, 1e-12 * max(1.0, fabs(y_center)))
   v_scale  = 1.0 / y_scale
   v_shift  = -y_center * v_scale
   ```

**Этап 3.2: Применение преобразований к данным:**
1. **Преобразование аппроксимирующих точек:**
   ```
   для каждой точки (x_i, f_i, σ_i):
       t_i = t_scale * x_i + t_shift
       v_i = v_scale * f_i + v_shift
       σ_i_normalized = σ_i * v_scale  // коррекция веса пропорционально масштабу y
   ```

2. **Преобразование отталкивающих точек:**
   ```
   для каждой точки (y_j, y_j^*, B_j):
       t_j = t_scale * y_j + t_shift
       v_j_forbidden = v_scale * y_j^* + v_shift
       // Вес B_j НЕ масштабируется — он управляет относительной силой барьера,
       // которая должна сохраняться в преобразованной системе координат
   ```

3. **Преобразование интерполяционных узлов:**
   ```
   для каждой точки (z_e, f_e):
       t_e = t_scale * z_e + t_shift
       v_e = v_scale * f_e + v_shift
       // Точность интерполяции должна сохраняться: |F(t_e) - v_e| < ε_interp
   ```

4. **Преобразование границ интервала:**
   ```
   t_a = t_scale * a + t_shift
   t_b = t_scale * b + t_shift
   // Гарантированно: t_a = -1.0, t_b = +1.0 при использовании [-1, 1] нормализации
   ```

**Этап 3.3: Коррекция параметров регуляризации:**
- Регуляризационный член зависит от масштаба второй производной:
  ```
  ∫[F''(x)]²dx = ∫[G''(t) · (dt/dx)²]² · (dx/dt) dt = (dt/dx)³ · ∫[G''(t)]² dt
  где G(t) = F(x(t)) — преобразованная функция
  ```
- Коррекция параметра:
  ```
  γ_normalized = γ_original · (x_range/2)³
  ```
- Это обеспечивает инвариантность «силы» регуляризации относительно масштаба координат

### Шаг 5.2.4: Реализация обратного преобразования коэффициентов полинома

**Проблема обратного преобразования:**
- После оптимизации получены коэффициенты `g_k` для полинома в нормализованных координатах: `G(t) = Σ g_k · t^k`
- Требуется получить коэффициенты `a_k` для исходного полинома: `F(x) = Σ a_k · x^k`
- Связь: `F(x) = y_center + y_scale · G( t_scale·x + t_shift )`

**Алгоритм для мономиального базиса:**
1. **Подстановка линейного преобразования:**
   ```
   G(t) = Σ_{k=0..n} g_k · (t_scale·x + t_shift)^k
   ```
2. **Разложение бинома Ньютона:**
   ```
   (t_scale·x + t_shift)^k = Σ_{l=0..k} C(k,l) · t_scale^l · t_shift^{k-l} · x^l
   где C(k,l) = k! / (l!·(k-l)!) — биномиальные коэффициенты
   ```
3. **Сборка коэффициентов исходного полинома:**
   ```
   для l от 0 до n:
       a_l_temp = Σ_{k=l..n} g_k · C(k,l) · t_scale^l · t_shift^{k-l}
   ```
4. **Применение масштаба ординаты:**
   ```
   для l от 0 до n:
       a_l = y_scale · a_l_temp
   a_0 += y_center  // добавление сдвига для константного члена
   ```

**Оптимизация вычислений:**
- Предварительно вычислить таблицу биномиальных коэффициентов `C(k,l)` для `k,l ≤ n` (сложность O(n²))
- Предварительно вычислить степени `t_shift^p` для `p = 0..n` и `t_scale^l` для `l = 0..n`
- Использовать динамическое программирование для избежания повторных вычислений

**Алгоритм для базиса Чебышёва:**
1. **Преобразование через рекуррентные соотношения:**
   - Полином Чебышёва в нормализованных координатах: `G(t) = Σ g_k · T_k(t)`
   - После обратного преобразования `t = t_scale·x + t_shift` базисные функции теряют ортогональность
   - Стратегия: преобразовать в мономиальный базис как промежуточный шаг, затем применить алгоритм выше

2. **Альтернатива — численное преобразование:**
   - Вычислить значения `G(t)` в `n+1` точках на `[t_a, t_b]`
   - Применить обратное преобразование координат и значений: `(x_i, F_i) = (x(t_i), y(G(t_i)))`
   - Решить интерполяционную задачу для получения коэффициентов `a_k`
   - Менее точно, но проще в реализации для сложных базисов

### Шаг 5.2.5: Интеграция с параметризацией с интерполяционными ограничениями

**Особенности преобразования параметризации `F(x) = P_int(x) + Q(x)·W(x)`:**
1. **Преобразование базисного полинома `P_int(x)`:**
   - Интерполяционные узлы преобразуются как описано в шаге 5.2.3
   - Построить новый интерполяционный полином `P_int_norm(t)` в нормализованных координатах
   - Хранить его в барицентрической форме для численной устойчивости

2. **Преобразование весового множителя `W(x) = Π(x - z_e)`:**
   - Корни преобразуются линейно: `τ_e = t_scale·z_e + t_shift`
   - Новый множитель: `W_norm(t) = Π(t - τ_e)`
   - Связь с исходным: `W(x) = (x_range/2)^m · W_norm(t)`, где `m` — число узлов

3. **Преобразование корректирующего полинома `Q(x)`:**
   - Степень сохраняется: `deg(Q_norm) = deg(Q) = n - m`
   - Коэффициенты преобразуются через алгоритм шага 5.2.4 с учётом масштабирующего множителя `(x_range/2)^m`

4. **Итоговая параметризация в нормализованных координатах:**
   ```
   G(t) = P_int_norm(t) + Q_norm(t) · W_norm(t)
   где:
     P_int_norm(t) = (P_int(x) - y_center) / y_scale
     Q_norm(t) = Q(x) · (x_range/2)^m / y_scale
   ```

### Шаг 5.2.6: Валидация корректности преобразований

**Тест 1: Инвариантность интерполяционных условий:**
```
для каждого узла (z_e, f_e):
    t_e = transform_x(z_e)
    v_e_computed = evaluate_normalized(t_e)
    v_e_expected = transform_y(f_e)
    проверить: |v_e_computed - v_e_expected| < 1e-12
```

**Тест 2: Инвариантность расстояний до барьеров:**
```
для каждой отталкивающей точки (y_j, y_j^*):
    δ_original = |y_j^* - F_original(y_j)|
    δ_normalized = |v_j^* - G(t_j)| · y_scale  // обратное масштабирование расстояния
    проверить: |δ_original - δ_normalized| / δ_original < 1e-10
```

**Тест 3: Инвариантность функционала (с точностью до коррекции γ):**
```
J_original = compute_functional(original_data, original_coeffs)
J_normalized = compute_functional(normalized_data, normalized_coeffs)
J_normalized_corrected = J_normalized * y_scale² + γ_correction_term
проверить: |J_original - J_normalized_corrected| / J_original < 1e-8
```

**Тест 4: Точность обратного преобразования коэффициентов:**
```
// Прямое преобразование
coeffs_norm = forward_transform(coeffs_original)
// Обратное преобразование
coeffs_recovered = backward_transform(coeffs_norm)
// Сравнение
проверить: ||coeffs_original - coeffs_recovered||_∞ < 1e-10 * ||coeffs_original||_∞
```

### Шаг 5.2.7: Обработка крайних случаев и адаптивная стратегия

**Случай 1: Вырожденный интервал по оси `x` (`x_range ≈ 0`):**
- Причина: все точки имеют одинаковую абсциссу (например, вертикальная линия)
- Действие:
  * Отказаться от полиномиальной аппроксимации по `x`
  * Предложить альтернативу: аппроксимация по параметру или использование сплайнов
  * Сгенерировать диагностическое сообщение с рекомендациями

**Случай 2: Константные данные по оси `y` (`y_scale ≈ 0`):**
- Причина: все значения функции одинаковы
- Действие:
  * Вернуть константный полином `F(x) = y_center`
  * Пропустить оптимизацию как тривиальную задачу
  * Проверить выполнение барьерных условий (если `y_center` близко к `y_j^*` — ошибка постановки)

**Случай 3: Смешанные масштабы в данных:**
- Причина: присутствуют как очень малые (`< 1e-6`), так и очень большие (`> 1e6`) значения
- Адаптивная стратегия:
  * Применить логарифмическое преобразование к значениям `y` перед линейной нормализацией
  * Для оси `x` использовать кусочно-линейное преобразование с разными масштабами для поддиапазонов
  * Предостережение: логарифмическое преобразование изменяет характер регуляризации (вторая производная)

**Случай 4: Необходимость сохранения физических единиц:**
- Причина: пользователь требует интерпретируемости коэффициентов в исходных единицах
- Действие:
  * Выполнить внутреннюю оптимизацию в нормализованных координатах
  * После сходимости применить обратное преобразование коэффициентов
  * Предоставить пользователю оба набора коэффициентов (нормализованные для отладки, исходные для интерпретации)

### Шаг 5.2.8: Оптимизация производительности преобразований

**Кэширование параметров преобразования:**
- Хранить параметры `t_scale`, `t_shift`, `v_scale`, `v_shift` в структуре `NormalizationParams`
- Кэшировать предвычисленные таблицы:
  * Биномиальные коэффициенты `C(k,l)` для обратного преобразования
  * Степени `t_shift^p` и `t_scale^l`
  * Матрицу преобразования коэффициентов размером `(n+1)×(n+1)`

**Ленивое вычисление обратного преобразования:**
- Откладывать обратное преобразование коэффициентов до момента, когда они действительно нужны:
  * Для визуализации результатов
  * Для экспорта в другие системы
  * Для вычисления производных в исходных координатах
- В процессе оптимизации работать исключительно с нормализованными коэффициентами

**Векторизация преобразования точек:**
- Применять преобразования к массивам точек через SIMD-инструкции:
  ```cpp
  // Псевдокод для векторизации
  для блока из 4 точек:
      загрузить x[0..3] в векторный регистр
      умножить на t_scale (одна SIMD-операция)
      добавить t_shift (одна SIMD-операция)
      сохранить t[0..3]
  ```
- Особенно эффективно для больших наборов данных (> 10⁴ точек)

Этот план обеспечивает надёжное, численно устойчивое и обратимое масштабирование данных, критически важное для успешной оптимизации полиномов высокой степени. Подход сохраняет математическую эквивалентность задачи в преобразованных координатах, обеспечивает точное восстановление исходных коэффициентов и интегрируется со всеми компонентами алгоритма смешанной аппроксимации, включая интерполяционные ограничения и барьерные условия.