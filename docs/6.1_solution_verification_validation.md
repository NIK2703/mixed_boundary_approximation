## Подшаг 6.1: Верификация условий — подробный план реализации на C++

### Шаг 6.1.1: Архитектура модуля верификации и его интеграция в конвейер

**Структура класса `SolutionVerifier`:**
- Инкапсулирует логику проверки всех условий задачи после завершения оптимизации
- Хранит ссылки на:
  * `const ConstrainedPolynomial&` — финальное решение
  * `const DataSet&` — исходные данные (точки, веса, запрещённые значения)
  * `const OptimizationResult&` — результаты оптимизации (значения функционала, история сходимости)
- Предоставляет методы:
  * `verify_interpolation()` — проверка точного выполнения интерполяционных условий
  * `verify_repulsion_safety()` — проверка безопасного расстояния до барьеров
  * `verify_numerical_stability()` — проверка отсутствия численных аномалий
  * `generate_verification_report()` — формирование структурированного отчёта
- Работает в режиме «строгой верификации» (любое нарушение = ошибка) или «гибкой верификации» (нарушения → предупреждения с рекомендациями)

**Точка интеграции в конвейер:**
- Вызывается немедленно после завершения оптимизации (шаг 4.3) и до возврата результата пользователю
- При обнаружении критических нарушений запускает автоматическую коррекцию (шаг 6.2) перед повторной верификацией
- Сохраняет результаты верификации в `OptimizationResult` для последующего анализа и логирования

### Шаг 6.1.2: Верификация интерполяционных условий с адаптивной точностью

**Математическая основа:**
- Для параметризации `F(x) = P_int(x) + Q(x)·W(x)` интерполяционные условия должны выполняться точно: `F(z_e) = f(z_e)` для всех `e = 1..m`
- Теоретически: `W(z_e) = 0` ⇒ `F(z_e) = P_int(z_e) = f(z_e)`
- Практически: численные ошибки округления приводят к ненулевым отклонениям

**Алгоритм верификации:**

1. **Вычисление отклонений в узлах интерполяции:**
   ```
   для каждого узла e = 1..m:
       F_ze = polynomial.evaluate(z_e)           // значение аппроксиманта
       δ_e  = F_ze - f(z_e)                      // алгебраическое отклонение
       |δ_e| = fabs(δ_e)                         // абсолютное отклонение
   ```

2. **Адаптивное определение порога точности:**
   - Базовый порог: `ε_interp_base = 1e-10`
   - Масштабирование под характеристики задачи:
     ```
     scale_y = max(1.0, 0.1 * (max|f(x_i)| + max|y_j^*| + max|f(z_e)|))
     ε_interp = max(ε_interp_base, 1e-12 * scale_y)
     ```
   - Коррекция на степень полинома (для высоких степеней ошибка округления растёт):
     ```
     ε_interp_effective = ε_interp * (1.0 + 0.05 * max(0, n - 15))
     ```

3. **Классификация результатов верификации:**
   - **ИДЕАЛЬНО:** `max|δ_e| < 0.1 · ε_interp_effective`
   - **УДОВЛЕТВОРИТЕЛЬНО:** `0.1 · ε_interp_effective ≤ max|δ_e| < ε_interp_effective`
   - **ПРЕДУПРЕЖДЕНИЕ:** `ε_interp_effective ≤ max|δ_e| < 10 · ε_interp_effective`
   - **КРИТИЧЕСКИЙ СБОЙ:** `max|δ_e| ≥ 10 · ε_interp_effective`

4. **Диагностика источника нарушения:**
   - Если нарушение только в одном узле → проверить корректность вычисления `W(z_e)` (должно быть близко к машинному нулю)
   - Если нарушение во всех узлах → проверить точность построения `P_int(x)` (барицентрические веса)
   - Логирование максимального отклонения и соответствующего узла для отладки

### Шаг 6.1.3: Верификация безопасности относительно отталкивающих точек

**Математическая основа:**
- Отталкивающие точки задают запрещённые значения: `F(y_j) ≠ y_j^*`
- Практически требуется минимальное безопасное расстояние: `|F(y_j) - y_j^*| ≥ ε_safe`
- Значение `ε_safe` определяется на этапе инициализации (шаг 5.1.2) и зависит от масштаба задачи

**Алгоритм верификации:**

1. **Вычисление расстояний до запрещённых значений:**
   ```
   для каждой отталкивающей точки j = 1..N_repulse:
       F_yj = polynomial.evaluate(y_j)
       δ_j  = F_yj - y_j^*                     // алгебраическое расстояние
       |δ_j| = fabs(δ_j)                       // абсолютное расстояние
   ```

2. **Определение адаптивного порога безопасности:**
   - Базовый порог: `ε_safe_base = 1e-8`
   - Масштабирование:
     ```
     scale_y = max(1.0, 0.1 * (max|f(x_i)| + max|y_j^*|))
     ε_safe = max(ε_safe_base, 1e-10 * scale_y)
     ```
   - Динамическая коррекция на основе силы барьера:
     ```
     если B_j > 1000:    // сильный барьер требует большего запаса
         ε_safe_j = 10.0 * ε_safe
     иначе если B_j < 10: // слабый барьер допускает меньший запас
         ε_safe_j = 0.5 * ε_safe
     иначе:
         ε_safe_j = ε_safe
     ```

3. **Классификация безопасности каждой точки:**
   - **БЕЗОПАСНО:** `|δ_j| ≥ 10 · ε_safe_j`
   - **ПРЕДУПРЕДИТЕЛЬНО:** `ε_safe_j ≤ |δ_j| < 10 · ε_safe_j`
   - **ОПАСНО:** `0.1 · ε_safe_j ≤ |δ_j| < ε_safe_j`
   - **КРИТИЧЕСКИ ОПАСНО:** `|δ_j| < 0.1 · ε_safe_j` (риск численного коллапса)

4. **Агрегированная оценка безопасности решения:**
   ```
   safety_score = (число_безопасных + 0.5·число_предупредительных) / N_repulse
   ```
   - Интерпретация:
     * `safety_score = 1.0` — все точки безопасны
     * `0.8 ≤ safety_score < 1.0` — решение приемлемо с незначительными рисками
     * `0.5 ≤ safety_score < 0.8` — требуется коррекция (шаг 6.2)
     * `safety_score < 0.5` — решение неприемлемо, необходима повторная оптимизация

5. **Диагностика критических точек:**
   - Для каждой опасной точки вычислить «потенциал барьера»:
     ```
     barrier_potential_j = B_j / |δ_j|^2
     ```
   - Точки с `barrier_potential_j > 1e10` классифицируются как «активные барьеры» — их влияние доминирует в функционале
   - Логирование топ-3 самых опасных точек с указанием расстояния и потенциала

### Шаг 6.1.4: Верификация численной стабильности решения

**Проверка 1: Отсутствие аномальных значений на интервале:**
1. **Генерация контрольной сетки:**
   ```
   N_grid = max(100, 10 * n)  // минимум 10 точек на степень полинома
   для p = 0..N_grid:
       x_p = a + p * (b - a) / N_grid
   ```

2. **Оценка значений и производных:**
   ```
   для каждой точки сетки x_p:
       F_p = polynomial.evaluate(x_p)
       F2_p = polynomial.second_derivative(x_p)
       
       если isnan(F_p) или isinf(F_p):
           пометить как КРИТИЧЕСКАЯ АНОМАЛИЯ
       
       если |F_p| > 1e10 * max|f(x_i)|:
           пометить как ЭКСТРЕМАЛЬНОЕ ЗНАЧЕНИЕ
       
       если |F2_p| > 1e6 * max|f(x_i)| / (b-a)^2:
           пометить как ЧРЕЗМЕРНАЯ КРИВИЗНА
   ```

3. **Агрегированная метрика стабильности:**
   ```
   stability_score = 1.0 - (число_аномалий + 0.1*число_экстремумов) / N_grid
   ```
   - Требование: `stability_score ≥ 0.95` для приемлемого решения

**Проверка 2: Ограниченность коэффициентов полинома:**
- Для мономиального базиса: `max|a_k| < 1e8` (защита от переполнения при вычислении высоких степеней)
- Для базиса Чебышёва: `max|c_k| < 1e6` (коэффициенты обычно меньше из-за ортогональности)
- При нарушении — предупреждение о потенциальной неустойчивости при экстраполяции

**Проверка 3: Устойчивость к малым возмущениям:**
- Вычислить решение на слегка сдвинутой сетке: `x_p' = x_p + 1e-8 * (b-a)`
- Сравнить значения: `|F(x_p) - F(x_p')| < 1e-6 * max|F|`
- При нарушении — признак плохой обусловленности решения

### Шаг 6.1.5: Анализ баланса компонент функционала

**Цель анализа:**
- Убедиться, что все компоненты функционала вносят сопоставимый вклад в оптимизацию
- Обнаружить доминирование одной компоненты, что указывает на дисбаланс весов или некорректную постановку задачи

**Алгоритм анализа:**

1. **Вычисление вкладов компонент:**
   ```
   J_approx_final  = compute_approximation_term()
   J_repulse_final = compute_repulsion_term()
   J_reg_final     = compute_regularization_term()
   J_total         = J_approx_final + J_repulse_final + J_reg_final
   ```

2. **Нормирование вкладов:**
   ```
   share_approx  = J_approx_final  / max(J_total, 1e-12)
   share_repulse = J_repulse_final / max(J_total, 1e-12)
   share_reg     = J_reg_final     / max(J_total, 1e-12)
   ```

3. **Классификация баланса:**
   - **ИДЕАЛЬНЫЙ БАЛАНС:** все доли в диапазоне `[0.1, 0.7]`
   - **УМЕРЕННЫЙ ДИСБАЛАНС:** одна доля в `[0.01, 0.1)` или `(0.7, 0.99]`, остальные сбалансированы
   - **СИЛЬНЫЙ ДИСБАЛАНС:** одна доля < 0.01 или > 0.99
   - **КРИТИЧЕСКИЙ ДИСБАЛАНС:** одна доля > 0.999 (другие компоненты игнорируются)

4. **Диагностика причин дисбаланса:**
   - Если `share_repulse ≈ 1.0`:
     * Причина: чрезмерно большие веса `B_j` или слишком близкое расположение барьеров
     * Рекомендация: уменьшить `B_j` или пересмотреть постановку барьерных условий
   
   - Если `share_reg ≈ 1.0`:
     * Причина: избыточная регуляризация (`γ` слишком велик)
     * Рекомендация: уменьшить `γ` в 2–5 раз и повторить оптимизацию
   
   - Если `share_approx ≈ 1.0`:
     * Причина: слабые барьеры (`B_j` слишком малы) или недостаточная регуляризация
     * Рекомендация: увеличить `B_j` или `γ` для обеспечения гладкости

5. **Динамический анализ по истории оптимизации:**
   - Построить график изменения долей компонент по итерациям
   - Обнаружить «переключение доминирования» (например, барьер доминировал в начале, затем уступил место аппроксимации)
   - Такое поведение указывает на корректную адаптацию оптимизатора к многоцелевой задаче

### Шаг 6.1.6: Формирование структурированного верификационного отчёта

**Структура отчёта:**
```
ВЕРИФИКАЦИЯ РЕШЕНИЯ (итерация 87, время 12.3 с)

1. ИНТЕРПОЛЯЦИОННЫЕ УСЛОВИЯ:
   • Статус: УДОВЛЕТВОРИТЕЛЬНО ✓
   • Макс. отклонение: 2.3e-14 (порог: 1e-10)
   • Худший узел: z_5 = 2.456 (отклонение +2.3e-14)
   • Диагностика: Точность ограничена машинной арифметикой (double)

2. БЕЗОПАСНОСТЬ ОТНОСИТЕЛЬНО БАРЬЕРОВ:
   • Статус: БЕЗОПАСНО ✓
   • Мин. расстояние: 0.123 (порог: 1e-8)
   • Худшая точка: y_3 = 3.789 (расстояние 0.123, вес B=100)
   • Активные барьеры: отсутствуют (макс. потенциал = 6.6e3)

3. ЧИСЛЕННАЯ СТАБИЛЬНОСТЬ:
   • Статус: СТАБИЛЬНО ✓
   • Аномалии на сетке 1000 точек: 0/1000
   • Макс. значение |F(x)|: 4.56 (масштаб данных: 5.21)
   • Макс. кривизна |F''(x)|: 3.21 (ожидаемый масштаб: 2.87)

4. БАЛАНС КРИТЕРИЕВ:
   • Аппроксимация:  45.2%  ████████████████████░░░░░░░░░░
   • Отталкивание:   36.1%  ████████████████░░░░░░░░░░░░░░░░
   • Регуляризация:  18.7%  ████████░░░░░░░░░░░░░░░░░░░░░░░░
   • Статус: ИДЕАЛЬНЫЙ БАЛАНС ✓

ИТОГОВЫЙ СТАТУС ВЕРИФИКАЦИИ: ПРИЕМЛЕМОЕ РЕШЕНИЕ ✓
Рекомендации: Решение готово к использованию без дополнительной коррекции.
```

**Коды статусов верификации:**
- `VERIFICATION_OK` — все условия выполнены в допустимых пределах
- `VERIFICATION_WARNING` — незначительные нарушения, решение приемлемо с оговорками
- `VERIFICATION_CRITICAL` — критические нарушения, требуется коррекция (шаг 6.2)
- `VERIFICATION_FAILED` — фатальные ошибки, необходимо перезапустить оптимизацию с изменёнными параметрами

### Шаг 6.1.7: Автоматическая классификация качества решения

**Многофакторная оценка:**
```
качество = 0.4 * (1.0 - нормированное_отклонение_интерполяции)
         + 0.3 * безопасность_барьеров
         + 0.2 * стабильность_решения
         + 0.1 * баланс_критериев

где все компоненты нормированы в [0, 1]
```

**Классификация по шкале качества:**
- `качество ≥ 0.95` → **ОТЛИЧНОЕ** решение (готово к использованию)
- `0.85 ≤ качество < 0.95` → **ХОРОШЕЕ** решение (рекомендуется визуальная проверка)
- `0.70 ≤ качество < 0.85` → **УДОВЛЕТВОРИТЕЛЬНОЕ** решение (требует коррекции параметров)
- `качество < 0.70` → **НЕПРИЕМЛЕМОЕ** решение (обязательна коррекция шага 6.2)

**Генерация рекомендаций на основе классификации:**
- Для **ОТЛИЧНОГО** решения: «Решение прошло все проверки. Рекомендуется использовать как есть.»
- Для **ХОРОШЕГО** решения: «Решение приемлемо. Для улучшения качества рассмотрите увеличение γ на 20%.»
- Для **УДОВЛЕТВОРИТЕЛЬНОГО** решения: «Обнаружены умеренные нарушения. Рекомендуется коррекция: [конкретные действия].»
- Для **НЕПРИЕМЛЕМОГО** решения: «Решение не удовлетворяет требованиям. Требуется обязательная коррекция параметров и повторная оптимизация.»

Этот план обеспечивает комплексную, количественную и интерпретируемую верификацию решения с детальной диагностикой каждого аспекта задачи смешанной аппроксимации. Подход сочетает строгие математические критерии с адаптивными порогами, учитывающими специфику конкретной задачи, и предоставляет пользователю прозрачную обратную связь для принятия обоснованных решений о пригодности полученного решения.