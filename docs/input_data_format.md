## Оптимальная схема входных данных для алгоритма смешанной аппроксимации

Предлагаю **гибридную многофайловую структуру** с разделением на конфигурацию, данные и метаданные. Такой подход обеспечивает модульность, человекочитаемость, машинную эффективность и расширяемость.

---

### Структура файлов проекта

```
project_name/
├── config.yaml          # Основная конфигурация задачи
├── data/
│   ├── approximation.csv    # Аппроксимирующие точки
│   ├── repulsion.csv        # Отталкивающие точки
│   └── interpolation.csv    # Интерполяционные узлы
├── metadata.json        # Расширенные метаданные (опционально)
└── README.md            # Документация задачи (опционально)
```

---

### Файл 1: `config.yaml` — основная конфигурация (человекочитаемый)

```yaml
# ========================================
# Конфигурация задачи смешанной аппроксимации
# Версия формата: 1.2
# ========================================

task:
  id: "experiment_2026_02_08_001"
  description: "Аппроксимация спектральных данных с запретной зоной при 3.5 эВ"
  created_at: "2026-02-08T14:30:00Z"
  author: "researcher@lab.org"

problem:
  # Основные параметры задачи
  polynomial_degree: 12                # Степень итогового полинома (n)
  interval:
    a: 0.0                             # Левая граница [a, b]
    b: 10.0                            # Правая граница [a, b]
  
  # Веса критериев (автоматическая нормализация применяется внутри алгоритма)
  weights:
    regularization: 0.15               # γ — параметр регуляризации гладкости
    # Веса для точек задаются в соответствующих CSV-файлах
  
  # Параметры численной стабильности
  numerical:
    epsilon_safe: 1e-8                 # Минимальное расстояние до барьеров
    epsilon_interp: 1e-10              # Точность интерполяции
    max_iterations: 1000               # Максимум итераций оптимизатора
    convergence_tol: 1e-8              # Порог сходимости по функционалу

data_sources:
  # Пути к файлам с данными (относительно расположения config.yaml)
  approximation: "data/approximation.csv"
  repulsion:     "data/repulsion.csv"
  interpolation: "data/interpolation.csv"

processing_options:
  # Автоматические преобразования перед оптимизацией
  normalize_coordinates: true          # Нормализация x → [-1, 1]
  normalize_values: true               # Нормализация y → [-1, 1]
  basis_type: "chebyshev"              # "monomial" или "chebyshev"
  
  # Стратегии инициализации
  initialization_strategy: "mnk_with_barrier_correction"
  # Допустимые значения:
  #   "mnk" — чистый МНК
  #   "mnk_with_barrier_correction" — МНК + коррекция барьеров (рекомендуется)
  #   "zero_correction" — нулевая коррекция (консервативно)
  #   "random_ensemble" — случайная инициализация с ансамблем

  # Диагностика и верификация
  enable_cross_validation: true        # Включить кросс-валидацию для оценки переобучения
  cv_folds: 5                          # Число фолдов для кросс-валидации
  enable_sensitivity_analysis: false   # Анализ чувствительности (дорогостоящий)

advanced:
  # Расширенные параметры оптимизатора (обычно не требуют изменения)
  lbfgs_memory: 10                     # Параметр памяти L-BFGS
  initial_step: 1.0                    # Начальный шаг линейного поиска
  barrier_smoothing: "quadratic"       # "quadratic", "logarithmic" или "hybrid"
```

---

### Файл 2: `data/approximation.csv` — аппроксимирующие точки

```csv
# Аппроксимирующие точки: минимизация |f(x) - F(x)|² / σ
# Формат: x, f(x), sigma
# sigma > 0 — вес обратно пропорционален дисперсии измерения
# Комментарии начинаются с '#'

x,f,sigma
0.5,1.234,0.05
1.0,2.345,0.03
1.5,3.127,0.07
2.0,3.891,0.04
2.5,4.512,0.06
# ... дополнительные точки
9.5,2.134,0.08
10.0,1.987,0.05
```

**Особенности формата:**
- Три обязательных колонки: `x`, `f`, `sigma`
- `sigma` интерпретируется как стандартное отклонение измерения
- Поддержка научной нотации: `1.23e-4`
- Пропуск строк с `#` в начале
- Автоматическое определение разделителя (`,`, `;`, `\t`)

---

### Файл 3: `data/repulsion.csv` — отталкивающие точки

```csv
# Отталкивающие точки: минимизация B / |y* - F(y)|²
# Формат: x, y_forbidden, B
# y_forbidden — ЗАПРЕЩЁННОЕ значение функции в точке x
# B > 0 — сила отталкивания (чем больше, тем сильнее барьер)

x,y_forbidden,B
3.5,5.0,1000.0      # Сильный барьер: избегать значения 5.0 при x=3.5
4.2,4.8,500.0       # Умеренный барьер
7.1,2.3,200.0       # Слабый барьер
```

**Критически важные замечания:**
- Колонка `y_forbidden` (не `f`) — это **целевое запрещённое значение**, а не измерение!
- При отсутствии колонки `y_forbidden` алгоритм интерпретирует как `y_forbidden = 0.0` с предупреждением
- Для запретных областей `[y_min, y_max]` создать две точки:
  ```
  x,y_forbidden,B
  3.5,4.9,1000.0   # Нижняя граница области
  3.5,5.1,1000.0   # Верхняя граница области
  ```

---

### Файл 4: `data/interpolation.csv` — интерполяционные узлы

```csv
# Интерполяционные узлы: точное выполнение F(z) = f(z)
# Формат: x, f
# Веса не используются — условия выполняются строго

x,f
0.0,1.0    # Граничное условие слева
5.0,6.5    # Внутренний узел
10.0,2.0   # Граничное условие справа
```

**Ограничения:**
- Максимум `n + 1` узлов для полинома степени `n`
- Узлы должны быть уникальными (с точностью до 1e-12)
- При нарушении ограничений алгоритм выдаст ошибку на этапе валидации (шаг 1.1)

---

### Файл 5 (опционально): `metadata.json` — расширенные метаданные

```json
{
  "schema_version": "1.0",
  "physical_context": {
    "domain": "spectroscopy",
    "units": {
      "x": "eV",
      "y": "absorbance",
      "sigma": "absorbance"
    },
    "experimental_setup": "UV-Vis spectrometer, 25°C"
  },
  "data_provenance": {
    "source_files": [
      "raw_spectrum_20260208.dat",
      "calibration_curve.txt"
    ],
    "preprocessing_steps": [
      "baseline_correction",
      "noise_filtering_sigma=0.1"
    ]
  },
  "quality_flags": {
    "approximation_points_verified": true,
    "repulsion_points_physically_justified": true,
    "interpolation_nodes_exact": true
  },
  "recommended_parameters": {
    "polynomial_degree_range": [8, 15],
    "gamma_range": [0.05, 0.5],
    "barrier_weights_range": [100, 1000]
  }
}
```

---

### Альтернативный формат: единый файл для простых задач

Для небольших задач (< 100 точек) допустим единый файл `task.mixed`:

```yaml
# Единый файл задачи смешанной аппроксимации
# Расширение: .mixed
# MIME-type: application/x-mixed-approximation

config:
  polynomial_degree: 8
  interval: [0.0, 10.0]
  weights:
    regularization: 0.1

data:
  approximation:
    - [x: 1.0, f: 2.3, sigma: 0.1]
    - [x: 2.0, f: 3.1, sigma: 0.2]
    # ...
  
  repulsion:
    - [x: 5.0, y_forbidden: 4.0, B: 500.0]
    # ...
  
  interpolation:
    - [x: 0.0, f: 1.0]
    - [x: 10.0, f: 2.0]
```

---

### Спецификация формата: ключевые принципы

| Принцип | Реализация | Преимущество |
|---------|------------|--------------|
| **Модульность** | Разделение конфигурации и данных | Лёгкое обновление данных без изменения параметров |
| **Человекочитаемость** | YAML для конфигурации, CSV для данных | Ручная правка в текстовом редакторе |
| **Машинная эффективность** | Чёткая структура колонок, поддержка потоковой обработки | Быстрая загрузка больших наборов (> 10⁶ точек) |
| **Валидация на этапе загрузки** | Схема JSON Schema для автоматической проверки | Раннее обнаружение ошибок формата |
| **Обратная совместимость** | Версионирование формата (`schema_version`) | Поддержка старых задач в новых версиях алгоритма |
| **Физическая интерпретируемость** | Метаданные с единицами измерения | Сохранение контекста эксперимента |
| **Расширяемость** | Опциональные секции `advanced`, `metadata` | Добавление новых функций без нарушения старых задач |

---

### Схема валидации (JSON Schema)

Для автоматической проверки корректности `config.yaml`:

```yaml
$schema: "https://json-schema.org/draft/2020-12/schema"
title: "Mixed Approximation Configuration Schema v1.2"
type: object
properties:
  task:
    type: object
    properties:
      id: { type: string, pattern: "^[a-zA-Z0-9_-]+$" }
      description: { type: string }
    required: [id]
  problem:
    type: object
    properties:
      polynomial_degree: { type: integer, minimum: 0, maximum: 100 }
      interval:
        type: object
        properties:
          a: { type: number }
          b: { type: number, exclusiveMinimum: { $data: "1/a" } }
        required: [a, b]
    required: [polynomial_degree, interval]
required: [task, problem]
```

---

### Рекомендации по использованию

1. **Для исследовательских задач:** Использовать многофайловую структуру + `metadata.json` для воспроизводимости
2. **Для промышленного применения:** Единый `.mixed` файл для упрощения развёртывания
3. **Для больших наборов данных (> 10⁵ точек):** 
   - Данные в бинарном формате HDF5/Arrow
   - Конфигурация остаётся в YAML для человекочитаемости
4. **Для автоматизированных пайплайнов:** Генерировать конфигурацию программно через шаблоны Jinja2

Эта схема обеспечивает оптимальный баланс между удобством использования, надёжностью и производительностью для задач смешанной аппроксимации любой сложности.